{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_SVC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRWiL_1Wj3Pt"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHuxvjC5kGWY",
        "outputId": "a634afcb-9860-423d-a36a-19668d545939"
      },
      "source": [
        "# mount google drive to access data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP1es7R4kJnI"
      },
      "source": [
        "# define paths\n",
        "# dataset: https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection\n",
        "path = \"/content/drive/My Drive/01 - Courses/04 - Machine Learning Engineer Nanodegree/brain_tumor_detection/data/dataset\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BrYucjAkSF5"
      },
      "source": [
        "# define parameters\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "img_size = (img_height, img_width)\n",
        "n_augmented_images = 10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOl0AS_zFMm4"
      },
      "source": [
        "# define augmentation layer (https://neptune.ai/blog/data-augmentation-in-python)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "     layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "     layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "     layers.experimental.preprocessing.RandomZoom(0.1)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP0jy4ZYFjms"
      },
      "source": [
        "def augment_image(image, n_augmented_images):\n",
        "  '''\n",
        "  Returns a list of augmented images for the given input image\n",
        "  Arguments:\n",
        "  image (array) - input image\n",
        "  number_of_images (int) - number of augmented images to return\n",
        "  Returns:\n",
        "  images (list) - list of augmented images\n",
        "  '''\n",
        "\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  images = []\n",
        "\n",
        "  for i in range(n_augmented_images):\n",
        "    augmented_image = data_augmentation(image)\n",
        "    images.append(np.array(augmented_image[0]).flatten())\n",
        "\n",
        "  return images"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBG3IhrYjKq"
      },
      "source": [
        "def preprocess_data(path, img_size, n_augmented_images):\n",
        "  '''\n",
        "  Reads in images classified into folders, resizes and scales them. Returns \n",
        "  those processed images as features and their associated labels as well.\n",
        "  Arguments:\n",
        "    path (str) - path to classified image folders\n",
        "    img_size (tuple) - tuple containing resized image height and width\n",
        "  Returns:\n",
        "    X (array) - features (brain scan images)\n",
        "    y (array) - feature labels (0 - no tumor, 1 - tumor)\n",
        "  '''\n",
        "\n",
        "  unsuccessful_files = {}\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for folder_name in os.listdir(path):\n",
        "    if folder_name == 'no':\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 1\n",
        "    folder_path = os.path.join(path, folder_name)\n",
        "  \n",
        "    for fname in os.listdir(folder_path):\n",
        "      fpath = os.path.join(folder_path, fname)\n",
        "      try:\n",
        "        img = cv2.imread(fpath)\n",
        "        img = cv2.resize(img, img_size)\n",
        "        img = img / 255.0\n",
        "        X += augment_image(img, n_augmented_images)\n",
        "        y += [label] * n_augmented_images\n",
        "\n",
        "      except Exception as e:\n",
        "        unsuccessful_files[fname] = e\n",
        "\n",
        "  if unsuccessful_files:\n",
        "    print(f'Error processing the following files:\\n')\n",
        "    for index, key in enumerate(unsuccessful_files, 1):\n",
        "      print(f'{index}. {key} - {unsuccessful_files[key]}')\n",
        "  else:\n",
        "    print('Successfully processed all images.')\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X, y"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb_rGvt6nZ1W",
        "outputId": "ecb57dbb-46c7-40a6-94a1-910a0b2ee012"
      },
      "source": [
        "# obtain features and labels\n",
        "X, y = preprocess_data(path, img_size, n_augmented_images)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully processed all images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMQ5Sk8zNshE",
        "outputId": "fe50526e-d1bc-4c95-8963-c9c9f789cf76"
      },
      "source": [
        "print(f'After augmentation, our dataset now has {len(X)} samples.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After augmentation, our dataset now has 2530 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU823r3EquDh"
      },
      "source": [
        "# split data into train, validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njJE4OIaWEOz",
        "outputId": "a72fb016-f9ac-44ef-d9bb-79613649d587"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "clf = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Learn the digits on the train subset\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkRr_cJmyS-b"
      },
      "source": [
        "# make predictions on the test set\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V1Scwi2dhEq",
        "outputId": "ae13f4db-cdc0-4921-e3b7-1893e7338fe8"
      },
      "source": [
        "# classifiation report\n",
        "from sklearn.metrics import classification_report , confusion_matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.61      0.67       243\n",
            "           1       0.78      0.86      0.82       390\n",
            "\n",
            "    accuracy                           0.76       633\n",
            "   macro avg       0.76      0.74      0.74       633\n",
            "weighted avg       0.76      0.76      0.76       633\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "27vYLAwrdv8Y",
        "outputId": "b5dbf50a-a38b-4317-a73d-65983822cd17"
      },
      "source": [
        "# confusion matrix\n",
        "actual_labels = ['no_tumor', 'tumor']\n",
        "pred_labels = ['predicted_no_tumor', 'predicted_tumor']\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "matrix_df = pd.DataFrame(matrix, index=actual_labels, columns=pred_labels)\n",
        "matrix_df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted_no_tumor</th>\n",
              "      <th>predicted_tumor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>no_tumor</th>\n",
              "      <td>149</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tumor</th>\n",
              "      <td>55</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          predicted_no_tumor  predicted_tumor\n",
              "no_tumor                 149               94\n",
              "tumor                     55              335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}