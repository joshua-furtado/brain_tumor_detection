{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_SVC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRWiL_1Wj3Pt"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQpOTG44I1C",
        "outputId": "c52e3064-ef3c-4413-bd56-e5a15e6b1ead"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHuxvjC5kGWY",
        "outputId": "d29a318c-dbc2-4bac-d49e-7b98b6597395"
      },
      "source": [
        "# mount google drive to access data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP1es7R4kJnI"
      },
      "source": [
        "# define paths\n",
        "# dataset: https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection\n",
        "path = \"/content/drive/My Drive/01 - Courses/04 - Machine Learning Engineer Nanodegree/brain_tumor_detection/data/dataset\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BrYucjAkSF5"
      },
      "source": [
        "# define parameters\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "img_size = (img_height, img_width)\n",
        "n_augmented_images = 12"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOl0AS_zFMm4"
      },
      "source": [
        "# define augmentation layer (https://neptune.ai/blog/data-augmentation-in-python)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "     layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "     layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "     layers.experimental.preprocessing.RandomZoom(0.1)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP0jy4ZYFjms"
      },
      "source": [
        "def augment_image(image, n_augmented_images):\n",
        "  '''\n",
        "  Returns a list of augmented images for the given input image\n",
        "  Arguments:\n",
        "  image (array) - input image\n",
        "  number_of_images (int) - number of augmented images to return\n",
        "  Returns:\n",
        "  images (list) - list of augmented images\n",
        "  '''\n",
        "\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  images = []\n",
        "\n",
        "  for i in range(n_augmented_images):\n",
        "    augmented_image = data_augmentation(image)\n",
        "    images.append(np.array(augmented_image[0]).flatten())\n",
        "\n",
        "  return images"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBG3IhrYjKq"
      },
      "source": [
        "def preprocess_data(path, img_size, n_augmented_images):\n",
        "  '''\n",
        "  Reads in images classified into folders, resizes and scales them. Returns \n",
        "  those processed images as features and their associated labels as well.\n",
        "  Arguments:\n",
        "    path (str) - path to classified image folders\n",
        "    img_size (tuple) - tuple containing resized image height and width\n",
        "  Returns:\n",
        "    X (array) - features (brain scan images)\n",
        "    y (array) - feature labels (0 - no tumor, 1 - tumor)\n",
        "  '''\n",
        "\n",
        "  unsuccessful_files = {}\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for folder_name in os.listdir(path):\n",
        "    if folder_name == 'no':\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 1\n",
        "    folder_path = os.path.join(path, folder_name)\n",
        "  \n",
        "    for fname in os.listdir(folder_path):\n",
        "      fpath = os.path.join(folder_path, fname)\n",
        "      try:\n",
        "        img = cv2.imread(fpath)\n",
        "        img = cv2.resize(img, img_size)\n",
        "        img = img / 255.0\n",
        "        X.append(img.flatten())\n",
        "        y.append(label)\n",
        "        X += augment_image(img, n_augmented_images)\n",
        "        y += [label] * n_augmented_images\n",
        "\n",
        "      except Exception as e:\n",
        "        unsuccessful_files[fname] = e\n",
        "\n",
        "  if unsuccessful_files:\n",
        "    print(f'Error processing the following files:\\n')\n",
        "    for index, key in enumerate(unsuccessful_files, 1):\n",
        "      print(f'{index}. {key} - {unsuccessful_files[key]}')\n",
        "  else:\n",
        "    print('Successfully processed all images.')\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb_rGvt6nZ1W",
        "outputId": "58a5364f-7b61-46e6-b163-d13d9fd6a360"
      },
      "source": [
        "# obtain features and labels\n",
        "X, y = preprocess_data(path, img_size, n_augmented_images)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully processed all images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMQ5Sk8zNshE",
        "outputId": "9fffbb58-22b1-4198-ec43-8c165ecf7aa2"
      },
      "source": [
        "print(f'After augmentation, our dataset now has {len(X)} samples.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After augmentation, our dataset now has 3289 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU823r3EquDh"
      },
      "source": [
        "# split data into train, validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njJE4OIaWEOz",
        "outputId": "3096f33f-c156-45bd-f688-7e8b2626ba64"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "clf = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Learn the digits on the train subset\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkRr_cJmyS-b"
      },
      "source": [
        "# make predictions on the test set\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V1Scwi2dhEq",
        "outputId": "21789768-a463-4c9d-8605-f2794e6ccbab"
      },
      "source": [
        "# classifiation report\n",
        "from sklearn.metrics import classification_report , confusion_matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.73       352\n",
            "           1       0.77      0.90      0.83       471\n",
            "\n",
            "    accuracy                           0.79       823\n",
            "   macro avg       0.80      0.77      0.78       823\n",
            "weighted avg       0.80      0.79      0.79       823\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "27vYLAwrdv8Y",
        "outputId": "cd0968cb-1b42-48f2-ede3-faa1ea983da2"
      },
      "source": [
        "# confusion matrix\n",
        "actual_labels = ['no_tumor', 'tumor']\n",
        "pred_labels = ['predicted_no_tumor', 'predicted_tumor']\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "matrix_df = pd.DataFrame(matrix, index=actual_labels, columns=pred_labels)\n",
        "matrix_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted_no_tumor</th>\n",
              "      <th>predicted_tumor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>no_tumor</th>\n",
              "      <td>227</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tumor</th>\n",
              "      <td>47</td>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          predicted_no_tumor  predicted_tumor\n",
              "no_tumor                 227              125\n",
              "tumor                     47              424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}